{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fa89537",
   "metadata": {},
   "source": [
    "# Tutorial 2: The Cornell Box\n",
    "\n",
    "**Description:** In this tutorial, we familiarize ourselves a bit more with basic Blender functionality by recreating the Cornell Box. The reflectance and geometric data for the Cornell box scene are available here: https://www.graphics.cornell.edu/online/box/data.html .\n",
    "\n",
    "**Requirement(s):** import_ipynb\n",
    "\n",
    "**Author:** Matthew O'Toole\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "97bfa1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "register_class(...):\n",
      "Info: Registering key-config preferences class: 'Prefs', bl_idname 'Blender' has been registered before, unregistering previous\n"
     ]
    }
   ],
   "source": [
    "import bpy\n",
    "import bmesh\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import import_ipynb\n",
    "\n",
    "from t001_hello_world import get_render\n",
    "\n",
    "# Clear scene\n",
    "if __name__ == '__main__':\n",
    "    bpy.ops.wm.read_factory_settings(use_empty=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d114195f",
   "metadata": {},
   "source": [
    "#### Part 1: Setting up the render engine\n",
    "\n",
    "In Blender, there are multiple render engines used to convert the 3D scene into 2D images. For computational imaging, it's critical to understand and configure\n",
    "the appropriate render engine to ensure radiometric accuracy and image fidelity. Blender offers three main render engines, each suited for different use cases depending on performance, realism, and interactivity needs:\n",
    "* `Cycles`: A physically-based path tracer that supports realistic lighting, reflections, caustics, global illumination, defocus, and motion blur (**high photorealism**).\n",
    "* `EEVEE`: A real-time rasterization engine that performs simple shading calculations (**limited photorealism**).\n",
    "* `Workbench`: A render engine optimized for speed that does not perform any shading calculations (**not photorealistic**).\n",
    "\n",
    "There are other third party renderers available for Blender as well, such as the following:\n",
    "* `LuxCoreRender` (https://luxcorerender.org/): A versatile physically-based renderer that supports (i) path tracing, (ii) bidirectional path tracing, (iii) photon mapping, (iv) Metropolis light transport, and (v) spectral rendering (among many other features).\n",
    "\n",
    "There are also Blender add-ons for exporting scenes into formats compatible with other notable renderers, including Mitsuba (https://github.com/mitsuba-renderer/mitsuba-blender) and PBRT (https://www.pbrt.org/resources).\n",
    "\n",
    "This tutorial relies on `Cycles`, a capable and well-supported renderer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "42f48a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Set render engine and resolution for ray tracing\n",
    "    bpy.context.scene.render.engine = 'CYCLES'\n",
    "    bpy.context.scene.render.resolution_x = 512\n",
    "    bpy.context.scene.render.resolution_y = 512\n",
    "    bpy.context.scene.render.image_settings.file_format = 'PNG'\n",
    "\n",
    "    # Do not reduce number of samples per pixel based on render noise\n",
    "    bpy.context.scene.cycles.use_adaptive_sampling = False \n",
    "\n",
    "    # Set number of samples to render at each pixel\n",
    "    bpy.context.scene.cycles.samples = 100\n",
    "\n",
    "    # Do not denoise the rendered image\n",
    "    bpy.context.scene.cycles.use_denoising = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c695d101",
   "metadata": {},
   "source": [
    "#### Part 2: Defining the materials\n",
    "\n",
    "Next, we will define the materials (i.e. reflectance functions) used by all the objects within the Cornell Box scene.  This includes three Lambertian materials and an area light source.\n",
    "\n",
    "To do this, we use Blender's Principled BSDF (bidirectional scattering distribution function).  Creating a perfectly Lambertian surface requires setting the Roughness value to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f9a50f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    emissive_material = bpy.data.materials.new(name='Emissive Material')\n",
    "    emissive_material.use_nodes = True\n",
    "    bsdf = emissive_material.node_tree.nodes['Principled BSDF']\n",
    "    bsdf.inputs['Emission Strength'].default_value = 50\n",
    "    bsdf.inputs['Roughness'].default_value = 1\n",
    "\n",
    "    white_material = bpy.data.materials.new(name='White Material')\n",
    "    white_material.use_nodes = True\n",
    "    bsdf = white_material.node_tree.nodes['Principled BSDF']\n",
    "    bsdf.inputs['Base Color'].default_value = (1, 1, 1, 1)\n",
    "    bsdf.inputs['Roughness'].default_value = 1\n",
    "\n",
    "    red_material = bpy.data.materials.new(name='Red Material')\n",
    "    red_material.use_nodes = True\n",
    "    bsdf = red_material.node_tree.nodes['Principled BSDF']\n",
    "    bsdf.inputs['Base Color'].default_value = (1, 0, 0, 1)\n",
    "    bsdf.inputs['Roughness'].default_value = 1\n",
    "\n",
    "    green_material = bpy.data.materials.new(name='Green Material')\n",
    "    green_material.use_nodes = True\n",
    "    bsdf = green_material.node_tree.nodes['Principled BSDF']\n",
    "    bsdf.inputs['Base Color'].default_value = (0, 1, 0, 1)\n",
    "    bsdf.inputs['Roughness'].default_value = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67effa30",
   "metadata": {},
   "source": [
    "#### Part 3: Defining the geometry\n",
    "\n",
    "The scene geometry consists of a set of objects, each one defined by an array of quads. The following arrays contain the position of 4N vertices to define N quads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "357708f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    floor = [\n",
    "        (552.8, 0.0,   0.0),\n",
    "        (  0.0, 0.0,   0.0),\n",
    "        (  0.0, 0.0, 559.2),\n",
    "        (549.6, 0.0, 559.2),\n",
    "    ]\n",
    "\n",
    "    # Define a small offset for the lights so that it is just below the ceiling.\n",
    "    epsilon = -0.001\n",
    "\n",
    "    light = [\n",
    "        (343.0, 548.8 + epsilon, 227.0), \n",
    "        (343.0, 548.8 + epsilon, 332.0),\n",
    "        (213.0, 548.8 + epsilon, 332.0),\n",
    "        (213.0, 548.8 + epsilon, 227.0),\n",
    "    ]\n",
    "\n",
    "    ceiling = [\n",
    "        (556.0, 548.8,   0.0),\n",
    "        (556.0, 548.8, 559.2),\n",
    "        (  0.0, 548.8, 559.2),\n",
    "        (  0.0, 548.8,   0.0),\n",
    "    ]\n",
    "\n",
    "    back_wall = [\n",
    "        (549.6,   0.0, 559.2),\n",
    "        (  0.0,   0.0, 559.2),\n",
    "        (  0.0, 548.8, 559.2),\n",
    "        (556.0, 548.8, 559.2),\n",
    "    ]\n",
    "\n",
    "    right_wall = [\n",
    "        (0.0,   0.0, 559.2), \n",
    "        (0.0,   0.0,   0.0),\n",
    "        (0.0, 548.8,   0.0),\n",
    "        (0.0, 548.8, 559.2),\n",
    "    ]\n",
    "\n",
    "    left_wall = [\n",
    "        (552.8,   0.0,   0.0),\n",
    "        (549.6,   0.0, 559.2),\n",
    "        (556.0, 548.8, 559.2),\n",
    "        (556.0, 548.8,   0.0),\n",
    "    ]\n",
    "\n",
    "    short_block = [\n",
    "        (130.0, 165.0,  65.0),\n",
    "        ( 82.0, 165.0, 225.0),\n",
    "        (240.0, 165.0, 272.0),\n",
    "        (290.0, 165.0, 114.0),\n",
    "\n",
    "        (290.0,   0.0, 114.0),\n",
    "        (290.0, 165.0, 114.0),\n",
    "        (240.0, 165.0, 272.0),\n",
    "        (240.0,   0.0, 272.0),\n",
    "\n",
    "        (130.0,   0.0,  65.0),\n",
    "        (130.0, 165.0,  65.0),\n",
    "        (290.0, 165.0, 114.0),\n",
    "        (290.0,   0.0, 114.0),\n",
    "\n",
    "        ( 82.0,   0.0, 225.0),\n",
    "        ( 82.0, 165.0, 225.0),\n",
    "        (130.0, 165.0,  65.0),\n",
    "        (130.0,   0.0,  65.0),\n",
    "\n",
    "        (240.0,   0.0, 272.0),\n",
    "        (240.0, 165.0, 272.0),\n",
    "        ( 82.0, 165.0, 225.0),\n",
    "        ( 82.0,   0.0, 225.0),\n",
    "    ]\n",
    "\n",
    "    tall_block = [\n",
    "        (423.0, 330.0, 247.0),\n",
    "        (265.0, 330.0, 296.0),\n",
    "        (314.0, 330.0, 456.0),\n",
    "        (472.0, 330.0, 406.0),\n",
    "\n",
    "        (423.0,   0.0, 247.0),\n",
    "        (423.0, 330.0, 247.0),\n",
    "        (472.0, 330.0, 406.0),\n",
    "        (472.0,   0.0, 406.0),\n",
    "\n",
    "        (472.0,   0.0, 406.0),\n",
    "        (472.0, 330.0, 406.0),\n",
    "        (314.0, 330.0, 456.0),\n",
    "        (314.0,   0.0, 456.0),\n",
    "\n",
    "        (314.0,   0.0, 456.0),\n",
    "        (314.0, 330.0, 456.0),\n",
    "        (265.0, 330.0, 296.0),\n",
    "        (265.0,   0.0, 296.0),\n",
    "\n",
    "        (265.0,   0.0, 296.0),\n",
    "        (265.0, 330.0, 296.0),\n",
    "        (423.0, 330.0, 247.0),\n",
    "        (423.0,   0.0, 247.0),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c52584e",
   "metadata": {},
   "source": [
    "#### Part 4: Converting vertex data to objects\n",
    "\n",
    "Given the materials and geometry data, it is now time to assemble the set of objects that make up the Cornell Box scene.  For each object, we define (i) the vertices, (ii) faces made from vertices, (iii) the material used by the object, and (iv) the parent object.\n",
    "\n",
    "Note: All child objects inherit the transformations from its parent object (e.g., 'Cornell Box'). For example, we scale all objects within the scene by adjusting the scale of the parent object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d6ee8aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_object(name, vertices, material, parent_obj=None):\n",
    "    mesh = bpy.data.meshes.new(name)\n",
    "    bm = bmesh.new()\n",
    "\n",
    "    for vertex in vertices:\n",
    "        bm.verts.new(vertex)\n",
    "\n",
    "    bm.verts.ensure_lookup_table()\n",
    "\n",
    "    for k in range(0, len(vertices), 4):\n",
    "        bm.faces.new((bm.verts[k+0], \n",
    "                      bm.verts[k+1], \n",
    "                      bm.verts[k+2], \n",
    "                      bm.verts[k+3]))\n",
    "\n",
    "    bm.to_mesh(mesh)\n",
    "    bm.free()\n",
    "\n",
    "    obj = bpy.data.objects.new(name, mesh)\n",
    "    bpy.context.collection.objects.link(obj)\n",
    "    obj.parent = parent_obj\n",
    "    obj.data.materials.append(material)\n",
    "\n",
    "    return\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parent_obj = bpy.data.objects.new('Cornell Box', None)\n",
    "    bpy.context.collection.objects.link(parent_obj)\n",
    "\n",
    "    create_object('floor',       floor,       white_material,    parent_obj)\n",
    "    create_object('light',       light,       emissive_material, parent_obj)\n",
    "    create_object('ceiling',     ceiling,     white_material,    parent_obj)\n",
    "    create_object('back_wall',   back_wall,   white_material,    parent_obj)\n",
    "    create_object('right_wall',  right_wall,  green_material,    parent_obj)\n",
    "    create_object('left_wall',   left_wall,   red_material,      parent_obj)\n",
    "    create_object('short_block', short_block, white_material,    parent_obj)\n",
    "    create_object('tall_block',  tall_block,  white_material,    parent_obj)\n",
    "\n",
    "    # Rescale the scene to a reasonable size\n",
    "    parent_obj.scale = (0.01, 0.01, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefab200",
   "metadata": {},
   "source": [
    "#### Part 4: Defining the camera\n",
    "\n",
    "Finally, to create the camera, we take an alternative approach than the one show in the previous tutorial.  We explicitly create a new camera data-block, link it to an object, and assign the object to the scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b8c32f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    camera_data = bpy.data.cameras.new(name='Camera')\n",
    "    camera_object = bpy.data.objects.new('Camera', camera_data)\n",
    "    bpy.context.scene.collection.objects.link(camera_object)\n",
    "    bpy.context.scene.camera = camera_object\n",
    "\n",
    "    camera_data.sensor_width = 25\n",
    "    camera_data.sensor_height = 25\n",
    "    camera_data.lens = 35\n",
    "\n",
    "    camera_object.location = (2.78, 2.73, -8.00)\n",
    "    camera_object.rotation_euler = (0, np.pi, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f6b4e3",
   "metadata": {},
   "source": [
    "#### Part 5: Rendering our result and saving the scene\n",
    "\n",
    "Using functionality defined in the previous tutorial, we render out the scene.  We also save the scene, as it will come in handy in future tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55269b0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected 'except' or 'finally' block (910290890.py, line 8)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[74]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mpath = \"./scenes/cornell_box.ipynb\"\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m expected 'except' or 'finally' block\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    plt.imshow(get_render(), origin='lower')\n",
    "\n",
    "    path = \"./scenes/cornell_box.ipynb\"\n",
    "    bpy.ops.wm.save_as_mainfile(filepath=path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb8fded",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blender",
   "language": "python",
   "name": "blender"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
